"""High-performance LLM manager for note classification."""

import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import yaml
import hashlib
import json
from functools import lru_cache

from llama_cpp import Llama
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

from ..core.models import PillarType, NoteType, CurationAction, QualityScore, PillarAnalysis

logger = logging.getLogger(__name__)
console = Console()


class LLMManager:
    """High-performance LLM manager with caching and parallel processing."""
    
    def __init__(self, config_path: Path = Path("config/models_config.yaml")):
        """Initialize the LLM manager."""
        self.config_path = config_path
        self.config = self._load_config()
        self.models: Dict[str, Llama] = {}
        self.cache: Dict[str, Dict] = {}
        self._initialize_models()
    
    def _load_config(self) -> Dict[str, Any]:
        """Load model configuration."""
        try:
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.error(f"Model config not found: {self.config_path}")
            raise
    
    def _initialize_models(self):
        """Initialize optimized LLM models."""
        # Use smaller, faster models for classification
        model_configs = {
            'fast_classification': {
                'path': 'models/llama-3.1-8b-instruct-q6_k.gguf',  # Could use smaller model
                'context_window': 2048,  # Smaller context for speed
                'max_tokens': 256,       # Shorter responses
                'temperature': 0.05,
                'top_p': 0.95,
                'n_gpu_layers': -1,
                'n_threads': 4
            },
            'detailed_analysis': {
                'path': 'models/llama-3.1-8b-instruct-q6_k.gguf',
                'context_window': 4096,  # Reduced from 8192
                'max_tokens': 512,       # Reduced from 1024
                'temperature': 0.1,
                'top_p': 0.9,
                'n_gpu_layers': -1,
                'n_threads': 8
            },
            'quick_filter': {
                'path': 'models/llama-3.1-8b-instruct-q6_k.gguf',  # Could use tiny model
                'context_window': 1024,  # Very small context
                'max_tokens': 64,        # Very short responses
                'temperature': 0.01,     # Very deterministic
                'top_p': 0.99,
                'n_gpu_layers': -1,
                'n_threads': 2
            }
        }
        
        for model_type, config in model_configs.items():
            try:
                model_path = Path(config['path'])
                if not model_path.exists():
                    logger.warning(f"Model not found: {model_path}")
                    continue
                
                self.models[model_type] = Llama(
                    model_path=str(model_path),
                    n_ctx=config['context_window'],
                    n_gpu_layers=config['n_gpu_layers'],
                    n_threads=config['n_threads'],
                    verbose=False
                )
                logger.info(f"Initialized {model_type} model: {model_path}")
                
            except Exception as e:
                logger.error(f"Failed to initialize {model_type} model: {e}")
    
    def _get_cache_key(self, content: str, task: str) -> str:
        """Generate cache key for content and task."""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        return f"{task}_{content_hash}"
    
    @lru_cache(maxsize=1000)
    def _cached_analysis(self, content_hash: str, task: str) -> Optional[Dict[str, Any]]:
        """Get cached analysis result."""
        return self.cache.get(f"{task}_{content_hash}")
    
    def _cache_result(self, content_hash: str, task: str, result: Dict[str, Any]):
        """Cache analysis result."""
        self.cache[f"{task}_{content_hash}"] = result
    
    def quick_filter(self, content: str) -> Tuple[bool, float]:
        """Quick filter to determine if note is worth detailed analysis."""
        if len(content) < 50:  # Very short notes
            return False, 0.0
        
        # Check for obvious indicators
        low_value_indicators = [
            'test', 'draft', 'temp', 'todo', 'reminder', 'note to self',
            'placeholder', 'template', 'example', 'sample'
        ]
        
        content_lower = content.lower()
        if any(indicator in content_lower for indicator in low_value_indicators):
            return False, 0.1
        
        # Quick AI check for relevance
        prompt = f"""Quick check: Is this note relevant to infrastructure, PPP, or digital transformation?

Content: {content[:500]}...

Answer with only: relevant/not_relevant confidence_score(0-1)"""
        
        try:
            model = self._get_model('quick_filter')
            if model:
                response = model(
                    prompt=prompt,
                    max_tokens=64,
                    temperature=0.01,
                    stop=["\n"]
                )
                
                if 'choices' in response:
                    result = response['choices'][0]['text'].strip()
                    if 'relevant' in result.lower():
                        # Extract confidence score
                        import re
                        confidence_match = re.search(r'(\d+\.?\d*)', result)
                        confidence = float(confidence_match.group(1)) if confidence_match else 0.5
                        return True, confidence
                
        except Exception as e:
            logger.warning(f"Quick filter failed: {e}")
        
        # Default to processing if filter fails
        return True, 0.5
    
    def analyze_notes_batch(self, notes_data: List[Tuple[Path, str]]) -> List[Dict[str, Any]]:
        """Analyze multiple notes in parallel."""
        results = []
        
        # Quick filter first
        filtered_notes = []
        for note_path, content in notes_data:
            should_process, confidence = self.quick_filter(content)
            if should_process:
                filtered_notes.append((note_path, content, confidence))
            else:
                results.append({
                    'file_path': note_path,
                    'analysis': self._create_default_analysis(),
                    'classification': {
                        'curation_action': 'delete',
                        'curation_reasoning': 'Quick filtered - low relevance',
                        'confidence': confidence
                    }
                })
        
        # Process filtered notes in parallel
        if filtered_notes:
            with ThreadPoolExecutor(max_workers=4) as executor:
                # Submit analysis tasks
                future_to_note = {
                    executor.submit(self._analyze_single_note, note_path, content, confidence): 
                    (note_path, content, confidence)
                    for note_path, content, confidence in filtered_notes
                }
                
                # Collect results
                for future in as_completed(future_to_note):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        note_path, content, confidence = future_to_note[future]
                        logger.error(f"Failed to analyze {note_path}: {e}")
                        results.append({
                            'file_path': note_path,
                            'analysis': self._create_default_analysis(),
                            'classification': {
                                'curation_action': 'archive',
                                'curation_reasoning': f'Analysis failed: {e}',
                                'confidence': 0.0
                            }
                        })
        
        return results
    
    def _analyze_single_note(self, file_path: Path, content: str, confidence: float) -> Dict[str, Any]:
        """Analyze a single note with caching."""
        # Check cache first
        content_hash = hashlib.md5(content.encode()).hexdigest()
        cached_analysis = self._cached_analysis(content_hash, 'analysis')
        cached_classification = self._cached_analysis(content_hash, 'classification')
        
        if cached_analysis and cached_classification:
            logger.debug(f"Using cached results for {file_path.name}")
            return {
                'file_path': file_path,
                'analysis': cached_analysis,
                'classification': cached_classification
            }
        
        # Perform analysis
        analysis_result = self._perform_analysis(content, file_path)
        classification_result = self._perform_classification(content, analysis_result)
        
        # Cache results
        self._cache_result(content_hash, 'analysis', analysis_result)
        self._cache_result(content_hash, 'classification', classification_result)
        
        return {
            'file_path': file_path,
            'analysis': analysis_result,
            'classification': classification_result
        }
    
    def analyze_note_content(self, content: str, file_path: Path) -> Dict[str, Any]:
        """Analyze note content using the analysis model."""
        try:
            model = self._get_model('detailed_analysis')
            if not model:
                return self._create_default_analysis()
            
            prompt = self._build_analysis_prompt(content, file_path)
            response = model(
                prompt=prompt,
                max_tokens=512,
                temperature=0.1,
                top_p=0.9,
                stop=["</s>", "###"]
            )
            
            if 'choices' in response:
                result_text = response['choices'][0]['text'].strip()
                return self._parse_analysis_response(result_text)
            else:
                return self._create_default_analysis()
                
        except Exception as e:
            logger.error(f"Analysis failed for {file_path}: {e}")
            return self._create_default_analysis()
    
    def classify_note(self, content: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Classify note based on analysis results."""
        try:
            model = self._get_model('fast_classification')
            if not model:
                return self._create_default_classification()
            
            prompt = self._build_classification_prompt(content, analysis)
            response = model(
                prompt=prompt,
                max_tokens=256,
                temperature=0.05,
                top_p=0.95,
                stop=["</s>", "###"]
            )
            
            if 'choices' in response:
                result_text = response['choices'][0]['text'].strip()
                return self._parse_classification_response(result_text)
            else:
                return self._create_default_classification()
                
        except Exception as e:
            logger.error(f"Classification failed: {e}")
            return self._create_default_classification()
    
    def _perform_analysis(self, content: str, file_path: Path) -> Dict[str, Any]:
        """Perform detailed content analysis."""
        # Optimized prompt for faster processing
        prompt = f"""Analyze this note for infrastructure/PPP relevance:

{content[:1500]}...

JSON response:
{{
    "primary_pillar": "pillar_type",
    "note_type": "note_type",
    "quality_scores": {{
        "relevance": 0.0-1.0,
        "depth": 0.0-1.0,
        "actionability": 0.0-1.0,
        "uniqueness": 0.0-1.0,
        "structure": 0.0-1.0
    }}
}}

Pillars: ppp_fundamentals, operational_risk, value_for_money, digital_transformation, governance_transparency
Types: literature_research, project_workflow, personal_reflection, technical_code, meeting_template, community_event"""
        
        try:
            model = self._get_model('detailed_analysis')
            if model:
                response = model(
                    prompt=prompt,
                    max_tokens=512,
                    temperature=0.1,
                    stop=["\n\n", "```"]
                )
                
                if 'choices' in response:
                    return self._parse_analysis_response(response['choices'][0]['text'].strip())
        except Exception as e:
            logger.error(f"Analysis failed for {file_path}: {e}")
        
        return self._create_default_analysis()
    
    def _perform_classification(self, content: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Perform classification with optimized prompt."""
        # Calculate overall score
        scores = analysis.get('quality_scores', {})
        overall_score = sum(scores.values()) / len(scores) if scores else 0.0
        
        # Optimized classification prompt
        prompt = f"""Classify this note (score: {overall_score:.2f}):

{content[:300]}...

Action: keep/refine/archive/delete
Reason: brief explanation
Confidence: 0.0-1.0

JSON: {{"action": "action", "reason": "reason", "confidence": 0.0}}"""
        
        try:
            model = self._get_model('fast_classification')
            if model:
                response = model(
                    prompt=prompt,
                    max_tokens=256,
                    temperature=0.05,
                    stop=["\n\n"]
                )
                
                if 'choices' in response:
                    return self._parse_classification_response(response['choices'][0]['text'].strip())
        except Exception as e:
            logger.error(f"Classification failed: {e}")
        
        return self._create_default_classification()
    
    def _get_model(self, model_type: str) -> Optional[Llama]:
        """Get a specific model by type."""
        return self.models.get(model_type)
    
    def _build_analysis_prompt(self, content: str, file_path: Path) -> str:
        """Build prompt for content analysis."""
        # Extract folder context
        folder_path = str(file_path.parent)
        folder_name = file_path.parent.name
        
        return f"""You are an expert knowledge management analyst specializing in infrastructure, PPP, and digital transformation.

Analyze the following note from a personal knowledge base:

File: {file_path.name}
Location: {folder_path}
Folder Context: {folder_name}
Content:
{content[:2000]}...

IMPORTANT: Consider the folder structure as thematic organization. The folder "{folder_name}" may indicate the note's domain or category. Use this context to better understand the note's purpose and classification.

Provide a detailed analysis in the following JSON format:
{{
    "word_count": <int>,
    "has_frontmatter": <bool>,
    "has_attachments": <bool>,
    "attachment_count": <int>,
    "primary_pillar": "<pillar_type>",
    "secondary_pillars": ["<pillar_type>", ...],
    "note_type": "<note_type>",
    "quality_scores": {{
        "relevance": <float 0-1>,
        "depth": <float 0-1>,
        "actionability": <float 0-1>,
        "uniqueness": <float 0-1>,
        "structure": <float 0-1>
    }},
    "pillar_analyses": [
        {{
            "pillar": "<pillar_type>",
            "relevance_score": <float 0-1>,
            "confidence": <float 0-1>,
            "reasoning": "<explanation>",
            "keywords_found": ["<keyword>", ...]
        }}
    ]
}}

Pillar types: ppp_fundamentals, operational_risk, value_for_money, digital_transformation, governance_transparency
Note types: literature_research, project_workflow, personal_reflection, technical_code, meeting_template, community_event

Consider the folder context when determining:
- Primary pillar (folder may indicate domain)
- Note type (folder may suggest content category)
- Quality scores (folder organization may indicate importance)
- Relevance to infrastructure consulting, PPP, digital transformation, and knowledge management"""

    def _build_classification_prompt(self, content: str, analysis: Dict[str, Any]) -> str:
        """Build prompt for note classification."""
        return f"""Based on the previous analysis, determine the best curation action for this note.

Analysis Summary:
- Primary Pillar: {analysis.get('primary_pillar', 'None')}
- Note Type: {analysis.get('note_type', 'None')}
- Overall Quality Score: {analysis.get('quality_scores', {}).get('overall_score', 0):.2f}
- Folder Context: {analysis.get('folder_context', 'None')}

Content Preview:
{content[:500]}...

Determine the appropriate curation action and provide reasoning in JSON format:
{{
    "curation_action": "<action>",
    "curation_reasoning": "<detailed explanation>",
    "confidence": <float 0-1>
}}

Curation actions:
- "keep": High-value content worth preserving as-is
- "refine": Good content that needs improvement/expansion
- "archive": Potentially useful but not immediately actionable
- "delete": Low value, redundant, or outdated content

Consider the note's relevance to infrastructure consulting, PPP, digital transformation, and knowledge management domains. The folder structure may indicate thematic importance or organizational value."""

    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """Parse analysis response from LLM."""
        try:
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            logger.warning(f"Could not parse analysis response: {e}")
        
        return self._create_default_analysis()
    
    def _parse_classification_response(self, response: str) -> Dict[str, Any]:
        """Parse classification response from LLM."""
        try:
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                parsed = json.loads(json_match.group())
                return {
                    'curation_action': parsed.get('action', 'archive'),
                    'curation_reasoning': parsed.get('reason', 'Unable to parse'),
                    'confidence': parsed.get('confidence', 0.0)
                }
        except Exception as e:
            logger.warning(f"Could not parse classification response: {e}")
        
        return self._create_default_classification()
    
    def _create_default_analysis(self) -> Dict[str, Any]:
        """Create default analysis when parsing fails."""
        return {
            "word_count": 0,
            "has_frontmatter": False,
            "has_attachments": False,
            "attachment_count": 0,
            "primary_pillar": None,
            "secondary_pillars": [],
            "note_type": None,
            "quality_scores": {
                "relevance": 0.0,
                "depth": 0.0,
                "actionability": 0.0,
                "uniqueness": 0.0,
                "structure": 0.0
            },
            "pillar_analyses": []
        }
    
    def _create_default_classification(self) -> Dict[str, Any]:
        """Create default classification when parsing fails."""
        return {
            "curation_action": "archive",
            "curation_reasoning": "Unable to parse classification response",
            "confidence": 0.0
        }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics."""
        return {
            'cache_size': len(self.cache),
            'models_loaded': len(self.models),
            'cache_hit_rate': self._calculate_cache_hit_rate()
        }
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate."""
        # This would need to be implemented with actual hit tracking
        return 0.0  # Placeholder 